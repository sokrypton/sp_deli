{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sp_deli_final.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "LbP_kCQoWCVx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load needed libraries"
      ]
    },
    {
      "metadata": {
        "id": "bZXjHgvT3NGz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.layers import *\n",
        "from keras.models import Sequential,Model\n",
        "from keras import backend as K\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JbXdNqlixoj3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Functions to save and load datasets"
      ]
    },
    {
      "metadata": {
        "id": "ZfnV4kAIZbMx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def save_data(filename,tmp):\n",
        "  fo = open(filename, \"w\")\n",
        "  for n in range(tmp[\"shape\"][0]):\n",
        "    print(tmp[\"name\"][n],tmp[\"group\"][n],end=\"\",file=fo)\n",
        "    for i in range(tmp[\"shape\"][1]):\n",
        "      print(\"\",end=\" \",file=fo)\n",
        "      print(\",\".join([str(i) for i in list(tmp[\"one_hot\"][n][i])]),end=\"\",file=fo)\n",
        "    print(\"\",file=fo)\n",
        "  fo.close()\n",
        "    \n",
        "def load_data(filename):\n",
        "  tmp = {\n",
        "      \"data_set\":filename.replace(\".txt\",\"\"),\n",
        "      \"name\":[],\n",
        "      \"group\":[],\n",
        "      \"one_hot\":[]\n",
        "  }\n",
        "  file = open(filename,\"r\")\n",
        "  for line in file:\n",
        "    val = line.rstrip(\"\\n\").split(\" \")\n",
        "    tmp[\"name\"].append(val[0])\n",
        "    tmp[\"group\"].append(val[1])\n",
        "    tmp[\"one_hot\"].append([])\n",
        "    \n",
        "    for n in range(2,len(val)):\n",
        "      tmp[\"one_hot\"][-1].append(val[n].split(\",\"))\n",
        "      \n",
        "  tmp[\"name\"] = np.array(tmp[\"name\"],np.str)\n",
        "  tmp[\"group\"] = np.array(tmp[\"group\"],np.str)\n",
        "  tmp[\"one_hot\"] = np.array(tmp[\"one_hot\"],np.float)\n",
        "  tmp[\"shape\"] = tmp[\"one_hot\"].shape\n",
        "  return tmp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "daaoC89GWV3a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Functions for plot generation"
      ]
    },
    {
      "metadata": {
        "id": "btRAY6GSm1Ay",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_z(z,loc,title=\"none\",legend=True):\n",
        "  x = z[:,0]\n",
        "  y = z[:,1]\n",
        "\n",
        "  for lo in np.unique(loc):\n",
        "    xx = []\n",
        "    yy = []\n",
        "    for i in range(z.shape[0]):\n",
        "      if lo == loc[i]:\n",
        "        xx.append(x[i])\n",
        "        yy.append(y[i])\n",
        "    plt.scatter(xx,yy,label=lo)\n",
        "\n",
        "  if title != \"none\": plt.title(title)\n",
        "  if legend == True:\n",
        "    plt.legend(bbox_to_anchor=(1, 0, 0.5, 1),loc=\"upper left\",)\n",
        "  \n",
        "def plot_mu_sg(mu,sg,loc,sample=100,alpha=0.5,title=\"none\",legend=True):\n",
        "  for lo in np.unique(loc):\n",
        "    xx = []\n",
        "    yy = []\n",
        "    for i in range(len(loc)):\n",
        "      if lo == loc[i]:\n",
        "        x,y = (mu[i] + np.random.normal(0,1,size=(sample,2)) * sg[i]).T\n",
        "        \n",
        "        xx += list(x)\n",
        "        yy += list(y)\n",
        "    plt.scatter(xx,yy,label=lo,alpha=alpha)\n",
        "\n",
        "  plt.scatter(mu[:,0],mu[:,1],s=30,facecolors='none',edgecolors='black',linewidths=1)\n",
        "  if title != \"none\": plt.title(title)\n",
        "  if legend == True:\n",
        "    plt.legend(bbox_to_anchor=(1, 0, 0.5, 1),loc=\"upper left\",)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CLajCkx3Wahs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Function to make VAE model"
      ]
    },
    {
      "metadata": {
        "id": "2PCUVvu7gntc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def mk_model(\n",
        "    original_dim,    # number of snps\n",
        "    cat,             # number of categories of one-hot-encoding\n",
        "    latent_dim=2,\n",
        "    \n",
        "    # encoder\n",
        "    en_dim=[100,100,100],\n",
        "    en_drop=[0.5,0.5,0.5],\n",
        "    \n",
        "    # decoder\n",
        "    de_dim=[100,100,100],  # number of neurons for each layer\n",
        "    de_drop=[0.5,0.5,0.5], # rate of dropout for each layer\n",
        "    \n",
        "    act = \"elu\" # activation function for each layer\n",
        "):\n",
        "  \n",
        "  def act_fn(fn,tensor):\n",
        "    if fn == \"leakyrelu\": return LeakyReLU()(tensor)\n",
        "    else: return Activation(fn)(tensor)\n",
        "  \n",
        "  half_cat = int(cat/2)\n",
        "  ########################################################################\n",
        "  # INPUT\n",
        "  ########################################################################  \n",
        "  x_in = Input(shape=(original_dim,cat),name=\"x_in\")\n",
        "  x_in_em = Dense(half_cat,use_bias=False,name=\"x_in_em\")(x_in)\n",
        "    \n",
        "  ########################################################################\n",
        "  # ENCODER :: Q(z|X)\n",
        "  ########################################################################\n",
        "  en = Flatten()(x_in_em)\n",
        "  en = BatchNormalization(scale=False,center=False)(en)\n",
        "  \n",
        "  for i in range(len(en_dim)):\n",
        "    en = Dense(en_dim[i])(en)\n",
        "    en = Dropout(en_drop[i])(en)\n",
        "    en = act_fn(act,en)\n",
        "    en = BatchNormalization(scale=False,center=False)(en)\n",
        "    \n",
        "  ########################################################################\n",
        "  # Z (Latent space)\n",
        "  ########################################################################  \n",
        "  Z_mu = Dense(latent_dim)(en)\n",
        "  Z_log_sigma_sq = Dense(latent_dim)(en)\n",
        "  \n",
        "  Z_sigma = Lambda(lambda x: K.exp(0.5*x))(Z_log_sigma_sq)\n",
        "  \n",
        "  Z = Lambda(lambda x: x[0]+x[1]*K.random_normal(K.shape(x[0])))([Z_mu,Z_sigma])\n",
        "  \n",
        "  ########################################################################\n",
        "  # DECODER :: P(X|z)\n",
        "  ########################################################################\n",
        "  de = Z\n",
        "  for i in range(len(de_dim)):\n",
        "    de = Dense(de_dim[i])(de)\n",
        "    de = Dropout(de_drop[i])(de)\n",
        "    de = act_fn(act,de)\n",
        "    de = BatchNormalization(scale=False,center=False)(de)\n",
        "  \n",
        "  de = Dense(original_dim*half_cat)(de)\n",
        "  ########################################################################\n",
        "  # OUTPUT\n",
        "  ########################################################################  \n",
        "  x_out_em = Reshape((-1,half_cat))(de)\n",
        "  x_out = Dense(cat,activation=\"softmax\")(x_out_em)\n",
        "  ########################################################################\n",
        "  \n",
        "  def vae_loss(kl_weight=0.5):\n",
        "    def loss(x_true, x_pred):\n",
        "      # mask out missing data!\n",
        "      mask = K.sum(x_in,axis=-1)\n",
        "\n",
        "      # sigma (or standard deviation), keeping close to 1\n",
        "      # mu (or mean), keeping close to 0\n",
        "      kl_loss = kl_weight * K.sum(K.square(Z_mu) + K.square(Z_sigma) - Z_log_sigma_sq - 1.0, axis=-1)\n",
        "\n",
        "      # reconstruction (categorical crossentropy)\n",
        "      recon = K.sum(keras.metrics.categorical_crossentropy(x_in,x_out) * mask, axis=-1)\n",
        "      \n",
        "      return K.mean(recon + kl_loss)\n",
        "    return loss\n",
        "    \n",
        "  def acc(x_true,x_pred):\n",
        "    mask = K.sum(x_in,axis=-1,keepdims=True)\n",
        "    acc = K.sum(K.square(x_in-x_out),axis=-1,keepdims=True)\n",
        "    return K.mean(1.0 - K.sqrt(K.sum(acc*mask,axis=1)/K.sum(mask,axis=1)))\n",
        "    \n",
        "  vae0 = Model([x_in],[x_out],name=\"vae0\")\n",
        "  vae0.compile(optimizer='adam', loss=vae_loss(0.1), metrics=[acc])\n",
        "  \n",
        "  vae1 = Model([x_in],[x_out],name=\"vae1\")\n",
        "  vae1.compile(optimizer='adam', loss=vae_loss(0.5), metrics=[acc])\n",
        "  \n",
        "  enc = Model([x_in],[Z_mu,Z_sigma],name=\"enc\")\n",
        "  return vae0,vae1,enc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p1Ys8lxCWd_o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "function to generate models, train, and plot the latent space (Z)"
      ]
    },
    {
      "metadata": {
        "id": "R0mzsdx30HsU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def do_it(data):\n",
        "  plt.rcParams['figure.figsize'] = [10, 10]\n",
        "  plt.style.use('seaborn-colorblind')\n",
        "\n",
        "  def gen(batch_size):\n",
        "    while True:\n",
        "      idx = np.random.randint(0,data[\"shape\"][0],size=batch_size)\n",
        "      tmp = data[\"one_hot\"][idx]\n",
        "      yield tmp,tmp\n",
        "\n",
        "  K.clear_session()\n",
        "  vae0,vae1,enc = mk_model(data[\"shape\"][1],data[\"shape\"][2])\n",
        "  loss_history = []\n",
        "  acc_history = []\n",
        "  \n",
        "  \n",
        "  # we do different batch_sizes: 1/4, 1/3, 1/2 and 1/1 of the data\n",
        "  # (similar to changing the temperature)\n",
        "  r = 4\n",
        "  for i in range(r):\n",
        "    f = 1/(r-i)\n",
        "    batch_size = int(data[\"shape\"][0] * f + 0.5)\n",
        "    steps = int(data[\"shape\"][0]/batch_size + 0.5)\n",
        "    epochs = int(1000 * f + 0.5)\n",
        "\n",
        "    for vae in (vae0,vae1):\n",
        "      print(\"-\")\n",
        "      his = vae.fit_generator(gen(batch_size), steps_per_epoch=steps, epochs=epochs, verbose=False)\n",
        "      loss_history += list(his.history['loss'])\n",
        "      acc_history += list(his.history['acc'])\n",
        "\n",
        "    if i == r-1:\n",
        "      plt.subplot(2, 2, 1)\n",
        "      plt.plot(np.arange(len(loss_history)),loss_history)\n",
        "      plt.ylabel(\"loss\")\n",
        "      plt.title(data[\"data_set\"])\n",
        "      plt.subplot(2, 2, 2)\n",
        "      plt.plot(np.arange(len(acc_history)),acc_history)\n",
        "      plt.ylabel(\"accuracy\")\n",
        "\n",
        "      vae_mu,vae_sg = enc.predict(data[\"one_hot\"])\n",
        "      plt.subplot(2, 2, 3)\n",
        "      plot_z(vae_mu,data[\"group\"],legend=False)\n",
        "      plt.subplot(2, 2, 4)\n",
        "      plot_mu_sg(vae_mu,vae_sg,data[\"group\"],sample=100)\n",
        "      plt.show()\n",
        "      \n",
        "  return(vae_mu,vae_sg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kh1xtQ9f4bqp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_sets = [\n",
        "    \"Metano_UCE_SNPs_50percent.txt\",\n",
        "    \"Metano_UCE_SNPs_70percent.txt\",\n",
        "    \"Phrynosoma_Leache_etal.txt\",\n",
        "    \"Uma_Gottscho_etal.txt\",\n",
        "]\n",
        "for data_set in data_sets:\n",
        "  mu,sg = do_it(load_data(\"data/\"+data_set))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}